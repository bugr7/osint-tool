import cloudscraper
from bs4 import BeautifulSoup
import time

# Ø¥Ù†Ø´Ø§Ø¡ scraper
scraper = cloudscraper.create_scraper(browser={
    'browser': 'chrome',
    'platform': 'windows',
    'mobile': False
})

# Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø¨Ø­Ø«
def search_bing(query):
    url = f"https://www.bing.com/search?q={query}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9"
    }
    res = scraper.get(url, headers=headers)
    if res.status_code == 200:
        soup = BeautifulSoup(res.text, "html.parser")
        links = [a["href"] for a in soup.select("li.b_algo h2 a") if a.get("href")]
        return links
    return []

def search_ddg(query):
    url = f"https://duckduckgo.com/html/?q={query}"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/120.0.0.0 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9"
    }
    res = scraper.get(url, headers=headers)
    if res.status_code == 200:
        soup = BeautifulSoup(res.text, "html.parser")
        links = [a["href"] for a in soup.select(".result__a") if a.get("href")]
        return links
    return []

# Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ù…Ø¹ fallback
def search(query, platform):
    print(f"\nğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ {platform}...")
    q = f"{query} site:{platform}.com"
    results = search_bing(q)

    # fallback Ø¥Ø°Ø§ Ù…Ø§ÙƒØ§Ù†Ø´ Ù†ØªØ§Ø¦Ø¬
    if not results:
        time.sleep(2)  # ØªÙ‡Ø¯Ø¦Ø©
        results = search_ddg(q)

    if results:
        for link in results:
            print("âœ…", link)
        return results
    else:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬.")
        return []

if __name__ == "__main__":
    name = input("[?] Ø£Ø¯Ø®Ù„ Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ù„Ù„Ù‚Ø¨ Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: ")
    platforms = ["youtube", "tiktok", "reddit", "linkedin", "facebook", "instagram"]

    all_results = []
    for p in platforms:
        links = search(name, p)
        all_results.extend(links)
        time.sleep(2)

    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    with open("results.txt", "w", encoding="utf-8") as f:
        for link in all_results:
            f.write(link + "\n")

    print("\nâœ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØªØ­ÙØ¸Øª ÙÙŠ results.txt")
