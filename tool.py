import requests
from bs4 import BeautifulSoup
from colorama import Fore, init, Style
import time
import platform
import json

# ====== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ÙˆÙ† ======
init(autoreset=True)

# ====== Ø´Ø¹Ø§Ø± Ø§Ù„Ø£Ø¯Ø§Ø© ======
banner = r"""
 /$$$$$$$                                   /$$$$$$$$
| $$__  $$                                 |_____ $$/
| $$  \ $$ /$$   /$$  /$$$$$$         /$$$$$$   /$$/
| $$$$$$$/| $$  | $$ /$$__  $$ /$$$$$$|____  $$ /$$/
| $$__  $$| $$  | $$| $$  \__/|______/ /$$$$$$$| $$
| $$  \ $$| $$  | $$| $$       /$$    /$$__  $$| $$
| $$  | $$|  $$$$$$/| $$      | $$   |  $$$$$$$| $$
|__/  |__/ \______/ |__/      |__/    \_______/|__/
"""
print(Fore.GREEN + banner)
print(Fore.RED + "[*] Ø£Ø¯Ø§Ø© Ø§Ù„Ø¨Ø­Ø« OSINT Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù…Ù†ØµØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©" + Fore.GREEN + "\n")

# ====== Ù…Ù†ØµØ§Øª Ø±Ø¦ÙŠØ³ÙŠØ© ======
PLATFORMS = {
    "Facebook": "facebook.com",
    "Instagram": "instagram.com",
    "YouTube": "youtube.com",
    "TikTok": "tiktok.com",
    "Twitter": "twitter.com",
    "Reddit": "reddit.com",
    "LinkedIn": "linkedin.com",
    "Pinterest": "pinterest.com",
    "Snapchat": "snapchat.com",
}

REQUEST_DELAY = 2.0  # Ø«Ø§Ù†ÙŠØ© Ø¨ÙŠÙ† ÙƒÙ„ Ø·Ù„Ø¨ Ù„Ù…Ù†Ø¹ Ø§Ù„Ø­Ø¬Ø¨

# ====== Ø¥Ù†Ø´Ø§Ø¡ Session Ø«Ø§Ø¨Øª ======
session = requests.Session()
session.headers.update({"User-Agent": "Mozilla/5.0"})

# ====== Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± DuckDuckGo HTML ======
def search_ddg(query, site=None, max_results=5):
    search_query = f"{query} site:{site}" if site else query
    url = "https://html.duckduckgo.com/html/"
    data = {"q": search_query}
    results = []

    try:
        response = session.post(url, headers=session.headers, data=data, timeout=15)
        soup = BeautifulSoup(response.text, "html.parser")
        links = soup.select(".result__a")[:max_results]
        for a in links:
            title = a.get_text()
            href = a.get("href")
            results.append({"title": title, "href": href})
    except Exception as e:
        print(Fore.RED + f"[!] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø«: {e}")
    return results

# ====== Ø¨Ø¯Ø§Ø¦Ù„ Ù„Ù„Ù…Ù†ØµØ§Øª Ø§Ù„ØµØ¹Ø¨Ø© ======
def alternative_search(query, platform_name, max_results=5):
    results = []
    try:
        if platform_name == "Twitter":
            # Nitter search
            nitter_url = f"https://nitter.net/search?f=tweets&q={requests.utils.quote(query)}"
            resp = session.get(nitter_url, timeout=15)
            soup = BeautifulSoup(resp.text, "html.parser")
            tweets = soup.select(".timeline-item .tweet-content")[:max_results]
            for t in tweets:
                text = t.get_text().strip()
                link_tag = t.find("a", href=True)
                link = "https://nitter.net" + link_tag["href"] if link_tag else ""
                results.append({"title": text, "href": link})

        elif platform_name == "Reddit":
            # old.reddit.com search JSON
            reddit_url = f"https://old.reddit.com/search.json?q={requests.utils.quote(query)}&sort=relevance"
            resp = session.get(reddit_url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
            data = resp.json()
            for item in data.get("data", {}).get("children", [])[:max_results]:
                post = item["data"]
                results.append({"title": post.get("title"), "href": "https://reddit.com" + post.get("permalink")})
        # LinkedIn, Pinterest, Snapchat â†’ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…
        elif platform_name in ["LinkedIn", "Pinterest", "Snapchat"]:
            results.append({"title": "[!] Ø§Ù„Ø¨Ø­Ø« Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†ØµØ© ÙŠØ­ØªØ§Ø¬ API Ø£Ùˆ Selenium", "href": ""})

    except Exception as e:
        print(Fore.RED + f"[!] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ {platform_name}: {e}")

    return results

# ====== Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ======
def run_checks(identifier):
    print(Fore.MAGENTA + "\n" + "="*60)
    print(Fore.MAGENTA + f"ðŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†: {identifier}")
    print(Fore.MAGENTA + "="*60 + "\n")

    for platform_name, domain in PLATFORMS.items():
        print(Fore.YELLOW + f"ðŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ {platform_name}...")
        # DuckDuckGo HTML Ù„Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
        if platform_name in ["Facebook", "Instagram", "YouTube", "TikTok"]:
            links = search_ddg(identifier, site=domain, max_results=5)
        else:
            # Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø£Ùˆ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª
            links = alternative_search(identifier, platform_name, max_results=5)

        count = len(links)
        print(Fore.GREEN + f"âœ… {platform_name}: {count}/5 Ù†ØªØ§Ø¦Ø¬")

        if links:
            for link in links:
                title = link['title']
                href = link['href']
                if href:
                    print(Fore.CYAN + f"   {title} -> {href}")
                else:
                    print(Fore.CYAN + f"   {title}")
        else:
            print(Fore.RED + "   Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬.")

        print(Fore.MAGENTA + "-"*60 + "\n")
        time.sleep(REQUEST_DELAY)

# ====== Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ======
def main():
    username = platform.node()
    os_name = platform.system() + " " + platform.release()

    while True:
        identifier = input(Fore.CYAN + "[?] Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ø¨Ø­Ø« (Ø£Ùˆ Ø§ÙƒØªØ¨ exit Ù„Ù„Ø®Ø±ÙˆØ¬): " + Style.RESET_ALL).strip()
        if identifier.lower() == "exit":
            print(Fore.GREEN + "\n[âœ”] ØªÙ… Ø§Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† Ø§Ù„Ø£Ø¯Ø§Ø©. Ø¥Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø¡ ðŸ‘‹")
            break
        if not identifier:
            print(Fore.RED + "[!] Ù„Ù… ÙŠØªÙ… Ø¥Ø¯Ø®Ø§Ù„ Ø£ÙŠ ÙƒÙ„Ù…Ø© Ù„Ù„Ø¨Ø­Ø«.")
            continue

        run_checks(identifier)

if __name__ == "__main__":
    main()
